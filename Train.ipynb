{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import cv2\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics as tm\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from ZeroShotDataset import ZeroShotDataset\n",
    "from params import *\n",
    "from DatasetModeling import *\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from LossFunc import *\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "from torch.utils.data import random_split\n",
    "from CLIPConditionedSegFormerModel import CLIPConditionedSegFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TrainParams.TRAIN_CSV_PATH)\n",
    "clip_processor = CLIPProcessor.from_pretrained('openai/clip-vit-base-patch16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>mask</th>\n",
       "      <th>label</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000558840.jpg</td>\n",
       "      <td>000000558840_0.jpg</td>\n",
       "      <td>hot dog</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000000558840.jpg</td>\n",
       "      <td>000000558840_1.jpg</td>\n",
       "      <td>bottle</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000000558840.jpg</td>\n",
       "      <td>000000558840_2.jpg</td>\n",
       "      <td>cup</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000000558840.jpg</td>\n",
       "      <td>000000558840_3.jpg</td>\n",
       "      <td>person</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000000558840.jpg</td>\n",
       "      <td>000000558840_4.jpg</td>\n",
       "      <td>spoon</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973173</th>\n",
       "      <td>000000581929.jpg</td>\n",
       "      <td>000000581929_973173.jpg</td>\n",
       "      <td>bush</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973174</th>\n",
       "      <td>000000581929.jpg</td>\n",
       "      <td>000000581929_973174.jpg</td>\n",
       "      <td>cage</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973175</th>\n",
       "      <td>000000581929.jpg</td>\n",
       "      <td>000000581929_973175.jpg</td>\n",
       "      <td>clouds</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973176</th>\n",
       "      <td>000000581929.jpg</td>\n",
       "      <td>000000581929_973176.jpg</td>\n",
       "      <td>grass</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973177</th>\n",
       "      <td>000000581929.jpg</td>\n",
       "      <td>000000581929_973177.jpg</td>\n",
       "      <td>tree</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>973178 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   image                     mask    label  category_id\n",
       "0       000000558840.jpg       000000558840_0.jpg  hot dog           58\n",
       "1       000000558840.jpg       000000558840_1.jpg   bottle           44\n",
       "2       000000558840.jpg       000000558840_2.jpg      cup           47\n",
       "3       000000558840.jpg       000000558840_3.jpg   person            1\n",
       "4       000000558840.jpg       000000558840_4.jpg    spoon           50\n",
       "...                  ...                      ...      ...          ...\n",
       "973173  000000581929.jpg  000000581929_973173.jpg     bush           97\n",
       "973174  000000581929.jpg  000000581929_973174.jpg     cage           99\n",
       "973175  000000581929.jpg  000000581929_973175.jpg   clouds          106\n",
       "973176  000000581929.jpg  000000581929_973176.jpg    grass          124\n",
       "973177  000000581929.jpg  000000581929_973177.jpg     tree          169\n",
       "\n",
       "[973178 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 64115\n",
      "36847 4560\n",
      "121 242 240.83625730994152\n"
     ]
    }
   ],
   "source": [
    "balanced_train_df = balance_dataset(train_df)\n",
    "\n",
    "# inductive_dataset_train = inductive_dataset(balanced_train_df, TrainParams.UNSEEN_CLASSES)\n",
    "# inductive_dataset_val = inductive_dataset(balanced_train_df, TrainParams.SEEN_CLASSES)\n",
    "\n",
    "# print(len(inductive_dataset_train), len(inductive_dataset_val))\n",
    "\n",
    "transductive_dataset_train = transductive_dataset(train_df, TrainParams.SEEN_CLASSES)\n",
    "transductive_dataset_val = transductive_dataset(train_df, TrainParams.UNSEEN_CLASSES)\n",
    "\n",
    "print(len(transductive_dataset_train), len(transductive_dataset_val))\n",
    "\n",
    "# print min and max frequencies\n",
    "label_freqs = balanced_train_df[\"label\"].value_counts()\n",
    "print(label_freqs.min(), label_freqs.max(), label_freqs.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProcessedDatasetStuff512/images/train/ ProcessedDatasetStuff512/masks/train/\n"
     ]
    }
   ],
   "source": [
    "print(TrainParams.DATASET_IMAGE_FOLDER_TRAIN, TrainParams.DATASET_MASK_FOLDER_TRAIN,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ZeroShotDataset(\n",
    "    # df = inductive_dataset_train, \n",
    "    df = transductive_dataset_train,\n",
    "    image_folder = TrainParams.DATASET_IMAGE_FOLDER_TRAIN,\n",
    "    mask_folder = TrainParams.DATASET_MASK_FOLDER_TRAIN,\n",
    "    image_size = TrainParams.IMAGE_DIM,\n",
    "    mask_size = TrainParams.MASK_SIZE,\n",
    "    templates = TrainParams.TEMPLATES, \n",
    "    unseen_classes = TrainParams.UNSEEN_CLASSES, \n",
    "    image_processor = clip_processor, \n",
    "    tokenizer = clip_processor.tokenizer, \n",
    "    filter_unseen = False,\n",
    "    filter_seen = False # True\n",
    ")\n",
    "\n",
    "val_dataset = ZeroShotDataset(\n",
    "    # df = inductive_dataset_val, \n",
    "    df = transductive_dataset_val,\n",
    "    image_folder = TrainParams.DATASET_IMAGE_FOLDER_TRAIN,\n",
    "    mask_folder = TrainParams.DATASET_MASK_FOLDER_TRAIN,\n",
    "    image_size = TrainParams.IMAGE_DIM,\n",
    "    mask_size = TrainParams.MASK_SIZE,\n",
    "    templates = TrainParams.TEMPLATES, \n",
    "    unseen_classes = TrainParams.UNSEEN_CLASSES, \n",
    "    image_processor = clip_processor, \n",
    "    tokenizer = clip_processor.tokenizer, \n",
    "    filter_unseen = False, # True\n",
    "    filter_seen = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 8\n",
      "Num workers: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Batch size:\", TrainParams.BATCH_SIZE)\n",
    "print(\"Num workers:\", TrainParams.NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 36847\n",
      "Number of val images: 4560\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training images: {len(train_dataset)}\")   \n",
    "print(f\"Number of val images: {len(val_dataset)}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=TrainParams.BATCH_SIZE, shuffle=True, collate_fn=train_dataset.collate_fn, num_workers=TrainParams.NUM_WORKERS)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=TrainParams.BATCH_SIZE, shuffle=False, collate_fn=val_dataset.collate_fn, num_workers=TrainParams.NUM_WORKERS)\n",
    "test_model = CLIPConditionedSegFormer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_iou',\n",
    "    filename='transformer-{epoch:02d}-{val_loss:.3f}-{val_iou:.2f}',\n",
    "    save_top_k=3,\n",
    "    mode='max',\n",
    "    # dirpath='checkpoints/',\n",
    "    save_last=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='gpu',\n",
    "    max_epochs=20,\n",
    "    callbacks=[\n",
    "        checkpoint_callback,\n",
    "        LearningRateMonitor(logging_interval='step')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                 | Params\n",
      "---------------------------------------------------\n",
      "0 | clip      | CLIPModel            | 149 M \n",
      "1 | segformer | ConditionedSegFormer | 13.4 M\n",
      "2 | neloss    | NELoss               | 0     \n",
      "3 | acc       | Accuracy             | 0     \n",
      "4 | dice      | DiceLoss             | 0     \n",
      "5 | iou       | IoULoss              | 0     \n",
      "6 | f1score   | F1Score              | 0     \n",
      "---------------------------------------------------\n",
      "13.4 M    Trainable params\n",
      "149 M     Non-trainable params\n",
      "163 M     Total params\n",
      "652.183   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc52e86cce5b419ab05e82500f1a3693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c9027e41304c128cdfc2ff4f73a038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31f3e48db2146e184a4198eb3e56242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 4606: 'val_iou' reached 0.23361 (best 0.23361), saving model to 'c:\\\\Users\\\\david\\\\OneDrive\\\\Documents\\\\GitHub\\\\TextualSegFormer\\\\lightning_logs\\\\version_23\\\\checkpoints\\\\transformer-epoch=00-val_loss=0.372-val_iou=0.23.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c4764dc6144790afb0c9255bd688a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 9212: 'val_iou' reached 0.24829 (best 0.24829), saving model to 'c:\\\\Users\\\\david\\\\OneDrive\\\\Documents\\\\GitHub\\\\TextualSegFormer\\\\lightning_logs\\\\version_23\\\\checkpoints\\\\transformer-epoch=01-val_loss=0.369-val_iou=0.25.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee55fc38ec94c68b36f6c740f577b4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 13818: 'val_iou' reached 0.26209 (best 0.26209), saving model to 'c:\\\\Users\\\\david\\\\OneDrive\\\\Documents\\\\GitHub\\\\TextualSegFormer\\\\lightning_logs\\\\version_23\\\\checkpoints\\\\transformer-epoch=02-val_loss=0.358-val_iou=0.26.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8c0f8726954f108c379f22eaa6c514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 18424: 'val_iou' reached 0.28276 (best 0.28276), saving model to 'c:\\\\Users\\\\david\\\\OneDrive\\\\Documents\\\\GitHub\\\\TextualSegFormer\\\\lightning_logs\\\\version_23\\\\checkpoints\\\\transformer-epoch=03-val_loss=0.339-val_iou=0.28.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664562f49f20429195b872184f7b2412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 23030: 'val_iou' reached 0.29395 (best 0.29395), saving model to 'c:\\\\Users\\\\david\\\\OneDrive\\\\Documents\\\\GitHub\\\\TextualSegFormer\\\\lightning_logs\\\\version_23\\\\checkpoints\\\\transformer-epoch=04-val_loss=0.334-val_iou=0.29.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069c6fa37d274eaa8f28954b3644349b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 27636: 'val_iou' reached 0.29798 (best 0.29798), saving model to 'c:\\\\Users\\\\david\\\\OneDrive\\\\Documents\\\\GitHub\\\\TextualSegFormer\\\\lightning_logs\\\\version_23\\\\checkpoints\\\\transformer-epoch=05-val_loss=0.343-val_iou=0.30.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f29fd526e949e89228b446e01095dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 32242: 'val_iou' reached 0.28883 (best 0.29798), saving model to 'c:\\\\Users\\\\david\\\\OneDrive\\\\Documents\\\\GitHub\\\\TextualSegFormer\\\\lightning_logs\\\\version_23\\\\checkpoints\\\\transformer-epoch=06-val_loss=0.342-val_iou=0.29.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfdcb0a0dbba434bb00ef7a76588c088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 36848: 'val_iou' reached 0.30694 (best 0.30694), saving model to 'c:\\\\Users\\\\david\\\\OneDrive\\\\Documents\\\\GitHub\\\\TextualSegFormer\\\\lightning_logs\\\\version_23\\\\checkpoints\\\\transformer-epoch=07-val_loss=0.338-val_iou=0.31.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42bcc7fb34e546518cf4a52aebb33ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 41454: 'val_iou' reached 0.31678 (best 0.31678), saving model to 'c:\\\\Users\\\\david\\\\OneDrive\\\\Documents\\\\GitHub\\\\TextualSegFormer\\\\lightning_logs\\\\version_23\\\\checkpoints\\\\transformer-epoch=08-val_loss=0.329-val_iou=0.32.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563d8c891acc4e8bb4d0857ea31620a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 46060: 'val_iou' reached 0.32275 (best 0.32275), saving model to 'c:\\\\Users\\\\david\\\\OneDrive\\\\Documents\\\\GitHub\\\\TextualSegFormer\\\\lightning_logs\\\\version_23\\\\checkpoints\\\\transformer-epoch=09-val_loss=0.335-val_iou=0.32.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a7c65107cd4b03940ec7869c4ca0ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 50666: 'val_iou' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ec92064f5543f3ae609ef277cf314e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 55272: 'val_iou' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9469354dc86d45f3bcc5ada7ab797451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 59878: 'val_iou' reached 0.31464 (best 0.32275), saving model to 'c:\\\\Users\\\\david\\\\OneDrive\\\\Documents\\\\GitHub\\\\TextualSegFormer\\\\lightning_logs\\\\version_23\\\\checkpoints\\\\transformer-epoch=12-val_loss=0.330-val_iou=0.31.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea00c4066e949c58ebf17ab28853c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 64484: 'val_iou' reached 0.32239 (best 0.32275), saving model to 'c:\\\\Users\\\\david\\\\OneDrive\\\\Documents\\\\GitHub\\\\TextualSegFormer\\\\lightning_logs\\\\version_23\\\\checkpoints\\\\transformer-epoch=13-val_loss=0.327-val_iou=0.32.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0034ba4476c74432887c6b45e20a5456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 69090: 'val_iou' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dacb5b28fc484028bfbed40fc6442606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 73696: 'val_iou' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da5acd0fbefc4e679576c1d57e15b52e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 78302: 'val_iou' reached 0.32064 (best 0.32275), saving model to 'c:\\\\Users\\\\david\\\\OneDrive\\\\Documents\\\\GitHub\\\\TextualSegFormer\\\\lightning_logs\\\\version_23\\\\checkpoints\\\\transformer-epoch=16-val_loss=0.337-val_iou=0.32.ckpt' as top 3\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(test_model, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
