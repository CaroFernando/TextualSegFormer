{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import cv2\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics as tm\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from ZeroShotDataset import ZeroShotDataset\n",
    "from params import *\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from LossFunc import *\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "from torch.utils.data import random_split\n",
    "from CLIPConditionedSegFormerModel import CLIPConditionedSegFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     test       acc      dice       iou        f1\n",
      "0  Unseen  0.825741  0.607357  0.303705  0.825741\n",
      "1    Seen  0.843713  0.720149  0.196095  0.843713\n",
      "2     All  0.842898  0.710173  0.205728  0.842898\n",
      "0.2383156333424745\n"
     ]
    }
   ],
   "source": [
    "prueba_df = pd.read_csv('test_results.csv')\n",
    "print(prueba_df)\n",
    "hiou = H_IoULoss()\n",
    "print(hiou(prueba_df['iou'][0], prueba_df['iou'][1]))\n",
    "# test_df.to_csv('test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_params = {\n",
    "    'Unseen' : {\n",
    "        'filter_unseen' : True,\n",
    "        'filter_seen' : False\n",
    "    },\n",
    "    'Seen' : {\n",
    "        'filter_unseen' : False,\n",
    "        'filter_seen' : True\n",
    "    },\n",
    "    'All' : {\n",
    "        'filter_unseen' : False,\n",
    "        'filter_seen' : False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, params, dataset_params):\n",
    "    dataset_params['filter_unseen'] = params['filter_unseen']\n",
    "    dataset_params['filter_seen'] = params['filter_seen']\n",
    "    ds = ZeroShotDataset(**dataset_params)\n",
    "\n",
    "    loader = DataLoader(ds, batch_size=TrainParams.BATCH_SIZE, num_workers=1, shuffle=True, collate_fn=ds.collate_fn)\n",
    "    trainer = pl.Trainer(accelerator='gpu', max_epochs=1)\n",
    "\n",
    "    results = trainer.test(model, dataloaders=loader)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataset_params, tests_params):\n",
    "    df = pd.DataFrame(columns=['test', 'acc', 'dice', 'miou', 'f1'])\n",
    "    for test_name, params in tests_params.items():\n",
    "        results = test(model, params, dataset_params)\n",
    "        df = df.append({\n",
    "            'test' : test_name,\n",
    "            'acc' : results[0]['test_acc'],\n",
    "            'dice' : results[0]['test_dice'],\n",
    "            'miou' : results[0]['test_iou'],\n",
    "            'f1' : results[0]['test_f1'],\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_processor = CLIPProcessor.from_pretrained('openai/clip-vit-base-patch16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLIPConditionedSegFormer()\n",
    "model.load_state_dict(torch.load(\"checkpoints/last-v5.ckpt\")[\"state_dict\"])\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ProcessedDatasetStuff512/csv/val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_params = {\n",
    "    'df': df,\n",
    "    'image_folder': TrainParams.DATASET_IMAGE_FOLDER,\n",
    "    'mask_folder': TrainParams.DATASET_MASK_FOLDER,\n",
    "    'image_size': TrainParams.IMAGE_DIM,\n",
    "    'mask_size': TrainParams.MASK_SIZE,\n",
    "    'templates': TrainParams.TEMPLATES, \n",
    "    'unseen_classes': TrainParams.UNSEEN_CLASSES, \n",
    "    'image_processor': clip_processor, \n",
    "    'tokenizer': clip_processor.tokenizer\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a86242f66a41769567d584b11e308e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8257412314414978     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_dice         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.607356607913971     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_f1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8257410526275635     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3037046790122986     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8257412314414978    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_dice        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.607356607913971    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_f1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8257410526275635    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3037046790122986    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00eac71c8bb147e2908b905b7994b301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.843712568283081     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_dice         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7201493382453918     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_f1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8437129259109497     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.19609537720680237    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.843712568283081    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_dice        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7201493382453918    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_f1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8437129259109497    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.19609537720680237   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b1c77f3c434f09bc8ee25674b7cc67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8428975939750671     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_dice         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7101734280586243     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_f1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8428979516029358     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_iou          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2057284116744995     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8428975939750671    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_dice        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7101734280586243    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_f1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8428979516029358    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_iou         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2057284116744995    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = test_model(model, dataset_params, tests_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_ds_params = dataset_params.copy()\n",
    "unseen_ds_params['filter_unseen'] = True\n",
    "unseen_ds_params['filter_seen'] = False\n",
    "\n",
    "unseen_ds = ZeroShotDataset(**unseen_ds_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[49406,   997,   533,   518,  2489,   268,  3487,   530,   518,  3562,\n",
      "           269, 49407,     0],\n",
      "        [49406,   589,   533,   637, 17143,   530,   518,  3562,   269, 49407,\n",
      "             0,     0,     0],\n",
      "        [49406,   320,  1125,   539,   320,  8675, 11673,   269, 49407,     0,\n",
      "             0,     0,     0],\n",
      "        [49406,   589,   533,   518,  2390,   268,  1010,   530,   518,  3562,\n",
      "           269, 49407,     0],\n",
      "        [49406,   589,   533,   320,  4558,   530,   518,  3562,   269, 49407,\n",
      "             0,     0,     0],\n",
      "        [49406,   997,   533,   518,  2390,   268,  1010,   530,   518,  3562,\n",
      "           269, 49407,     0],\n",
      "        [49406,   320,  7998,   530,   518,  3562,   269, 49407,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [49406,   589,   533,   320,  1125,   539,   320,  8675,  3814,   269,\n",
      "         49407,     0,     0],\n",
      "        [49406,   320,  1125,   539,   320,  8675, 38930,   269, 49407,     0,\n",
      "             0,     0,     0],\n",
      "        [49406,   320,  1125,   539,   320,  8675, 38930,   269, 49407,     0,\n",
      "             0,     0,     0],\n",
      "        [49406,   589,   533,   320,  1125,   539,   320,  2442,  2390,   268,\n",
      "          1010,   269, 49407],\n",
      "        [49406,   320,  1125,   539,   320,  7220,   268,  3487,   269, 49407,\n",
      "             0,     0,     0],\n",
      "        [49406,   589,   533,   320,  1125,   539,   320,  8675,  2489,   268,\n",
      "          3487,   269, 49407],\n",
      "        [49406,   589,   533,   320,  1125,   539,   320,  2442,  2390,   268,\n",
      "          1010,   269, 49407],\n",
      "        [49406,   997,   533,   320,  2489,   268,  3487,   530,   518,  3562,\n",
      "           269, 49407,     0],\n",
      "        [49406,   589,   533,   518,  3814,   530,   518,  3562,   269, 49407,\n",
      "             0,     0,     0]])\n",
      "torch.Size([16, 3, 512, 512]) torch.Size([16, 3, 224, 224]) torch.Size([16, 13]) torch.Size([16, 1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "unseen_loader = DataLoader(unseen_ds, batch_size=TrainParams.BATCH_SIZE, shuffle=True, collate_fn=unseen_ds.collate_fn)\n",
    "x, x_c, condition, y = next(iter(unseen_loader))\n",
    "# condition = condition.unsqueeze(0)\n",
    "print(x.shape, x_c.shape, condition.shape, y.shape)\n",
    "# condition = clip_processor.tokenizer.encode(\"a photo of a tv\")\n",
    "# condition = torch.tensor(condition).long()\n",
    "# pred = model(x.unsqueeze(0), x_c.unsqueeze(0), condition.unsqueeze(0))\n",
    "pred = model(x, x_c, condition)\n",
    "pred = torch.sigmoid(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 clip_processor.tokenizer.decode(condition)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">e:\\miniconda3\\envs\\AI\\lib\\site-packages\\transformers\\tokenization_utils_base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3486</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decode</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3483 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Convert inputs to python lists</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3484 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>token_ids = to_py_obj(token_ids)                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3485 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3486 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._decode(                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3487 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>token_ids=token_ids,                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3488 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>skip_special_tokens=skip_special_tokens,                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3489 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>clean_up_tokenization_spaces=clean_up_tokenization_spaces,                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">e:\\miniconda3\\envs\\AI\\lib\\site-packages\\transformers\\tokenization_utils_fast.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">549</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_decode</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">546 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">547 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(token_ids, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>):                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">548 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>token_ids = [token_ids]                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>549 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>text = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._tokenizer.decode(token_ids, skip_special_tokens=skip_special_tokens   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">550 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">551 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>clean_up_tokenization_spaces = (                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">552 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>clean_up_tokenization_spaces                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">e:\\miniconda3\\envs\\AI\\lib\\site-packages\\transformers\\models\\clip\\tokenization_clip_fast.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">117</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">new_decode_method</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">114 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>orig_decode_method = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.backend_tokenizer.decode                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">new_decode_method</span>(*args, **kwargs):                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>117 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>text = orig_decode_method(*args, **kwargs)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">118 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>text = text.replace(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.backend_tokenizer.model.end_of_word_suffix, <span style=\"color: #808000; text-decoration-color: #808000\">\" \"</span>).st   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">119 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> text                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">120 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span>argument <span style=\"color: #008000; text-decoration-color: #008000\">'ids'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'list'</span> object cannot be interpreted as an integer\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 clip_processor.tokenizer.decode(condition)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33me:\\miniconda3\\envs\\AI\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m:\u001b[94m3486\u001b[0m in \u001b[92mdecode\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3483 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Convert inputs to python lists\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3484 \u001b[0m\u001b[2m│   │   \u001b[0mtoken_ids = to_py_obj(token_ids)                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3485 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3486 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._decode(                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3487 \u001b[0m\u001b[2m│   │   │   \u001b[0mtoken_ids=token_ids,                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3488 \u001b[0m\u001b[2m│   │   │   \u001b[0mskip_special_tokens=skip_special_tokens,                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3489 \u001b[0m\u001b[2m│   │   │   \u001b[0mclean_up_tokenization_spaces=clean_up_tokenization_spaces,                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33me:\\miniconda3\\envs\\AI\\lib\\site-packages\\transformers\\tokenization_utils_fast.py\u001b[0m:\u001b[94m549\u001b[0m in \u001b[92m_decode\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m546 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m547 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(token_ids, \u001b[96mint\u001b[0m):                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m548 \u001b[0m\u001b[2m│   │   │   \u001b[0mtoken_ids = [token_ids]                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m549 \u001b[2m│   │   \u001b[0mtext = \u001b[96mself\u001b[0m._tokenizer.decode(token_ids, skip_special_tokens=skip_special_tokens   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m550 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m551 \u001b[0m\u001b[2m│   │   \u001b[0mclean_up_tokenization_spaces = (                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m552 \u001b[0m\u001b[2m│   │   │   \u001b[0mclean_up_tokenization_spaces                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33me:\\miniconda3\\envs\\AI\\lib\\site-packages\\transformers\\models\\clip\\tokenization_clip_fast.py\u001b[0m:\u001b[94m117\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mnew_decode_method\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2m│   │   \u001b[0morig_decode_method = \u001b[96mself\u001b[0m.backend_tokenizer.decode                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mnew_decode_method\u001b[0m(*args, **kwargs):                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m117 \u001b[2m│   │   │   \u001b[0mtext = orig_decode_method(*args, **kwargs)                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m118 \u001b[0m\u001b[2m│   │   │   \u001b[0mtext = text.replace(\u001b[96mself\u001b[0m.backend_tokenizer.model.end_of_word_suffix, \u001b[33m\"\u001b[0m\u001b[33m \u001b[0m\u001b[33m\"\u001b[0m).st   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m119 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m text                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m120 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0margument \u001b[32m'ids'\u001b[0m: \u001b[32m'list'\u001b[0m object cannot be interpreted as an integer\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clip_processor.tokenizer.decode(condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 plt.imshow(image.permute(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>))                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'image'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 plt.imshow(image.permute(\u001b[94m1\u001b[0m, \u001b[94m2\u001b[0m, \u001b[94m0\u001b[0m))                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'image'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.imshow(image.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span>plt.subplot(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 # set range to [0,1] for matplotlib</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3 plt.imshow(mask[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>], vmin=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>, vmax=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>plt.subplot(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span>plt.imshow(pred[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>][<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>].detach().numpy(), vmin=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>, vmax=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'mask'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m3\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0mplt.subplot(\u001b[94m1\u001b[0m, \u001b[94m2\u001b[0m, \u001b[94m1\u001b[0m)                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m\u001b[2m# set range to [0,1] for matplotlib\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3 plt.imshow(mask[\u001b[94m0\u001b[0m], vmin=\u001b[94m0\u001b[0m, vmax=\u001b[94m1\u001b[0m)                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0mplt.subplot(\u001b[94m1\u001b[0m, \u001b[94m2\u001b[0m, \u001b[94m2\u001b[0m)                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0mplt.imshow(pred[\u001b[94m0\u001b[0m][\u001b[94m0\u001b[0m].detach().numpy(), vmin=\u001b[94m0\u001b[0m, vmax=\u001b[94m1\u001b[0m)                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m6 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'mask'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASAAAAGiCAYAAABH+xtTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAYvklEQVR4nO3cb2yV9f3/8VdbOKcYacF1PS3sYAMG/0Nnka4gIS5nNtHUcWOxE0M74p+pnVFONqEiVEQpc4w1kSKxU/GGjjqjxkhTp52NUbuQFJroBAwWbWd2DjSOc1iRFno+3xv7cfzVtspV275beD6S60Y/uz7nend6np5/PSnOOScAMJBqPQCA8xcBAmCGAAEwQ4AAmCFAAMwQIABmCBAAMwQIgBkCBMAMAQJgxnOA3n33XZWUlGjGjBlKSUnRa6+99p17mpubdc0118jv9+uSSy7Rzp07hzEqgHON5wB1d3dr/vz5qq2tPavzDx8+rJtuuknXX3+92tra9MADD+iOO+7Qm2++6XlYAOeWlO/zx6gpKSl69dVXtWzZsiHPWb16tXbv3q2PPvooufbLX/5Sx44dU2Nj43AvDeAcMGm0L9DS0qJQKNRvrbi4WA888MCQe3p6etTT05P8OZFI6Msvv9QPfvADpaSkjNaoAIbgnNPx48c1Y8YMpaaO3EvHox6gSCSiQCDQby0QCCgej+urr77SlClTBuyprq7Whg0bRns0AB51dnbqRz/60Yjd3qgHaDgqKysVDoeTP8diMc2aNUudnZ3KyMgwnAw4P8XjcQWDQU2dOnVEb3fUA5STk6NoNNpvLRqNKiMjY9BHP5Lk9/vl9/sHrGdkZBAgwNBIvwQy6p8DKioqUlNTU7+1t956S0VFRaN9aQDjnOcA/fe//1VbW5va2tok/e9t9ra2NnV0dEj639OnsrKy5Pl333232tvb9eCDD+rAgQPavn27XnrpJa1atWpkfgMAE5fz6J133nGSBhzl5eXOOefKy8vd0qVLB+zJz893Pp/PzZ492z333HOerhmLxZwkF4vFvI4LYASM1n3we30OaKzE43FlZmYqFovxGhBgYLTug/wtGAAzBAiAGQIEwAwBAmCGAAEwQ4AAmCFAAMwQIABmCBAAMwQIgBkCBMAMAQJghgABMEOAAJghQADMECAAZggQADMECIAZAgTADAECYIYAATBDgACYIUAAzBAgAGYIEAAzBAiAGQIEwAwBAmCGAAEwQ4AAmCFAAMwQIABmCBAAMwQIgBkCBMAMAQJghgABMEOAAJghQADMECAAZggQADMECIAZAgTADAECYIYAATBDgACYIUAAzBAgAGYIEAAzBAiAGQIEwAwBAmCGAAEwQ4AAmCFAAMwQIABmCBAAMwQIgBkCBMAMAQJghgABMEOAAJghQADMDCtAtbW1ysvLU3p6ugoLC7Vnz55vPb+mpkaXXnqppkyZomAwqFWrVunkyZPDGhjAucNzgOrr6xUOh1VVVaW9e/dq/vz5Ki4u1pEjRwY9/8UXX9SaNWtUVVWl/fv365lnnlF9fb0eeuih7z08gInNc4C2bt2qO++8UytXrtQVV1yhHTt26IILLtCzzz476PkffPCBFi9erOXLlysvL0833HCDbr311u981ATg3OcpQL29vWptbVUoFPr6BlJTFQqF1NLSMuieRYsWqbW1NRmc9vZ2NTQ06MYbbxzyOj09PYrH4/0OAOeeSV5O7urqUl9fnwKBQL/1QCCgAwcODLpn+fLl6urq0nXXXSfnnE6fPq277777W5+CVVdXa8OGDV5GAzABjfq7YM3Nzdq0aZO2b9+uvXv36pVXXtHu3bu1cePGIfdUVlYqFoslj87OztEeE4ABT4+AsrKylJaWpmg02m89Go0qJydn0D3r1q3TihUrdMcdd0iSrr76anV3d+uuu+7S2rVrlZo6sIF+v19+v9/LaAAmIE+PgHw+nwoKCtTU1JRcSyQSampqUlFR0aB7Tpw4MSAyaWlpkiTnnNd5AZxDPD0CkqRwOKzy8nItWLBACxcuVE1Njbq7u7Vy5UpJUllZmWbOnKnq6mpJUklJibZu3aof//jHKiws1KFDh7Ru3TqVlJQkQwTg/OQ5QKWlpTp69KjWr1+vSCSi/Px8NTY2Jl+Y7ujo6PeI5+GHH1ZKSooefvhhffHFF/rhD3+okpISPf744yP3WwCYkFLcBHgeFI/HlZmZqVgspoyMDOtxgPPOaN0H+VswAGYIEAAzBAiAGQIEwAwBAmCGAAEwQ4AAmCFAAMwQIABmCBAAMwQIgBkCBMAMAQJghgABMEOAAJghQADMECAAZggQADMECIAZAgTADAECYIYAATBDgACYIUAAzBAgAGYIEAAzBAiAGQIEwAwBAmCGAAEwQ4AAmCFAAMwQIABmCBAAMwQIgBkCBMAMAQJghgABMEOAAJghQADMECAAZggQADMECIAZAgTADAECYIYAATBDgACYIUAAzBAgAGYIEAAzBAiAGQIEwAwBAmCGAAEwQ4AAmCFAAMwQIABmCBAAMwQIgBkCBMAMAQJghgABMEOAAJgZVoBqa2uVl5en9PR0FRYWas+ePd96/rFjx1RRUaHc3Fz5/X7NnTtXDQ0NwxoYwLljktcN9fX1CofD2rFjhwoLC1VTU6Pi4mIdPHhQ2dnZA87v7e3Vz372M2VnZ+vll1/WzJkz9fnnn2vatGkjMT+ACSzFOee8bCgsLNS1116rbdu2SZISiYSCwaDuu+8+rVmzZsD5O3bs0B/+8AcdOHBAkydPHtaQ8XhcmZmZisViysjIGNZtABi+0boPenoK1tvbq9bWVoVCoa9vIDVVoVBILS0tg+55/fXXVVRUpIqKCgUCAV111VXatGmT+vr6hrxOT0+P4vF4vwPAucdTgLq6utTX16dAINBvPRAIKBKJDLqnvb1dL7/8svr6+tTQ0KB169bpj3/8ox577LEhr1NdXa3MzMzkEQwGvYwJYIIY9XfBEomEsrOz9fTTT6ugoEClpaVau3atduzYMeSeyspKxWKx5NHZ2TnaYwIw4OlF6KysLKWlpSkajfZbj0ajysnJGXRPbm6uJk+erLS0tOTa5Zdfrkgkot7eXvl8vgF7/H6//H6/l9EATECeHgH5fD4VFBSoqakpuZZIJNTU1KSioqJB9yxevFiHDh1SIpFIrn3yySfKzc0dND4Azh+en4KFw2HV1dXp+eef1/79+3XPPfeou7tbK1eulCSVlZWpsrIyef4999yjL7/8Uvfff78++eQT7d69W5s2bVJFRcXI/RYAJiTPnwMqLS3V0aNHtX79ekUiEeXn56uxsTH5wnRHR4dSU7/uWjAY1JtvvqlVq1Zp3rx5mjlzpu6//36tXr165H4LABOS588BWeBzQICtcfE5IAAYSQQIgBkCBMAMAQJghgABMEOAAJghQADMECAAZggQADMECIAZAgTADAECYIYAATBDgACYIUAAzBAgAGYIEAAzBAiAGQIEwAwBAmCGAAEwQ4AAmCFAAMwQIABmCBAAMwQIgBkCBMAMAQJghgABMEOAAJghQADMECAAZggQADMECIAZAgTADAECYIYAATBDgACYIUAAzBAgAGYIEAAzBAiAGQIEwAwBAmCGAAEwQ4AAmCFAAMwQIABmCBAAMwQIgBkCBMAMAQJghgABMEOAAJghQADMECAAZggQADMECIAZAgTADAECYIYAATBDgACYIUAAzAwrQLW1tcrLy1N6eroKCwu1Z8+es9q3a9cupaSkaNmyZcO5LIBzjOcA1dfXKxwOq6qqSnv37tX8+fNVXFysI0eOfOu+zz77TL/97W+1ZMmSYQ8L4NziOUBbt27VnXfeqZUrV+qKK67Qjh07dMEFF+jZZ58dck9fX59uu+02bdiwQbNnz/7Oa/T09Cgej/c7AJx7PAWot7dXra2tCoVCX99AaqpCoZBaWlqG3Pfoo48qOztbt99++1ldp7q6WpmZmckjGAx6GRPABOEpQF1dXerr61MgEOi3HggEFIlEBt3z3nvv6ZlnnlFdXd1ZX6eyslKxWCx5dHZ2ehkTwAQxaTRv/Pjx41qxYoXq6uqUlZV11vv8fr/8fv8oTgZgPPAUoKysLKWlpSkajfZbj0ajysnJGXD+p59+qs8++0wlJSXJtUQi8b8LT5qkgwcPas6cOcOZG8A5wNNTMJ/Pp4KCAjU1NSXXEomEmpqaVFRUNOD8yy67TB9++KHa2tqSx80336zrr79ebW1tvLYDnOc8PwULh8MqLy/XggULtHDhQtXU1Ki7u1srV66UJJWVlWnmzJmqrq5Wenq6rrrqqn77p02bJkkD1gGcfzwHqLS0VEePHtX69esViUSUn5+vxsbG5AvTHR0dSk3lA9YAvluKc85ZD/Fd4vG4MjMzFYvFlJGRYT0OcN4ZrfsgD1UAmCFAAMwQIABmCBAAMwQIgBkCBMAMAQJghgABMEOAAJghQADMECAAZggQADMECIAZAgTADAECYIYAATBDgACYIUAAzBAgAGYIEAAzBAiAGQIEwAwBAmCGAAEwQ4AAmCFAAMwQIABmCBAAMwQIgBkCBMAMAQJghgABMEOAAJghQADMECAAZggQADMECIAZAgTADAECYIYAATBDgACYIUAAzBAgAGYIEAAzBAiAGQIEwAwBAmCGAAEwQ4AAmCFAAMwQIABmCBAAMwQIgBkCBMAMAQJghgABMEOAAJghQADMECAAZggQADMECIAZAgTADAECYGZYAaqtrVVeXp7S09NVWFioPXv2DHluXV2dlixZounTp2v69OkKhULfej6A84fnANXX1yscDquqqkp79+7V/PnzVVxcrCNHjgx6fnNzs2699Va98847amlpUTAY1A033KAvvvjiew8PYGJLcc45LxsKCwt17bXXatu2bZKkRCKhYDCo++67T2vWrPnO/X19fZo+fbq2bdumsrKyQc/p6elRT09P8ud4PK5gMKhYLKaMjAwv4wIYAfF4XJmZmSN+H/T0CKi3t1etra0KhUJf30BqqkKhkFpaWs7qNk6cOKFTp07poosuGvKc6upqZWZmJo9gMOhlTAAThKcAdXV1qa+vT4FAoN96IBBQJBI5q9tYvXq1ZsyY0S9i31RZWalYLJY8Ojs7vYwJYIKYNJYX27x5s3bt2qXm5malp6cPeZ7f75ff7x/DyQBY8BSgrKwspaWlKRqN9luPRqPKycn51r1btmzR5s2b9fbbb2vevHneJwVwzvH0FMzn86mgoEBNTU3JtUQioaamJhUVFQ2574knntDGjRvV2NioBQsWDH9aAOcUz0/BwuGwysvLtWDBAi1cuFA1NTXq7u7WypUrJUllZWWaOXOmqqurJUm///3vtX79er344ovKy8tLvlZ04YUX6sILLxzBXwXAROM5QKWlpTp69KjWr1+vSCSi/Px8NTY2Jl+Y7ujoUGrq1w+snnrqKfX29uoXv/hFv9upqqrSI4888v2mBzChef4ckIXR+gwCgLMzLj4HBAAjiQABMEOAAJghQADMECAAZggQADMECIAZAgTADAECYIYAATBDgACYIUAAzBAgAGYIEAAzBAiAGQIEwAwBAmCGAAEwQ4AAmCFAAMwQIABmCBAAMwQIgBkCBMAMAQJghgABMEOAAJghQADMECAAZggQADMECIAZAgTADAECYIYAATBDgACYIUAAzBAgAGYIEAAzBAiAGQIEwAwBAmCGAAEwQ4AAmCFAAMwQIABmCBAAMwQIgBkCBMAMAQJghgABMEOAAJghQADMECAAZggQADMECIAZAgTADAECYIYAATBDgACYIUAAzBAgAGYIEAAzBAiAmWEFqLa2Vnl5eUpPT1dhYaH27Nnzref/9a9/1WWXXab09HRdffXVamhoGNawAM4tngNUX1+vcDisqqoq7d27V/Pnz1dxcbGOHDky6PkffPCBbr31Vt1+++3at2+fli1bpmXLlumjjz763sMDmNhSnHPOy4bCwkJde+212rZtmyQpkUgoGAzqvvvu05o1awacX1paqu7ubr3xxhvJtZ/85CfKz8/Xjh07Br1GT0+Penp6kj/HYjHNmjVLnZ2dysjI8DIugBEQj8cVDAZ17NgxZWZmjtwNOw96enpcWlqae/XVV/utl5WVuZtvvnnQPcFg0P3pT3/qt7Z+/Xo3b968Ia9TVVXlJHFwcIyz49NPP/WSjO80SR50dXWpr69PgUCg33ogENCBAwcG3ROJRAY9PxKJDHmdyspKhcPh5M/Hjh3TxRdfrI6OjpGt7yg681+MifSojZnHxkSc+cyzkIsuumhEb9dTgMaK3++X3+8fsJ6ZmTlh/oGdkZGRwcxjgJnHRmrqyL5x7unWsrKylJaWpmg02m89Go0qJydn0D05OTmezgdw/vAUIJ/Pp4KCAjU1NSXXEomEmpqaVFRUNOieoqKifudL0ltvvTXk+QDOI15fNNq1a5fz+/1u586d7uOPP3Z33XWXmzZtmotEIs4551asWOHWrFmTPP/99993kyZNclu2bHH79+93VVVVbvLkye7DDz8862uePHnSVVVVuZMnT3od1wwzjw1mHhujNbPnADnn3JNPPulmzZrlfD6fW7hwofvHP/6R/N+WLl3qysvL+53/0ksvublz5zqfz+euvPJKt3v37u81NIBzg+fPAQHASOFvwQCYIUAAzBAgAGYIEAAz4yZAE/ErPrzMXFdXpyVLlmj69OmaPn26QqHQd/6Oo8Hr/89n7Nq1SykpKVq2bNnoDjgIrzMfO3ZMFRUVys3Nld/v19y5c8f83w+vM9fU1OjSSy/VlClTFAwGtWrVKp08eXKMppXeffddlZSUaMaMGUpJSdFrr732nXuam5t1zTXXyO/365JLLtHOnTu9X9j6bTjn/vfZIp/P55599ln3z3/+0915551u2rRpLhqNDnr++++/79LS0twTTzzhPv74Y/fwww97/mzRWM+8fPlyV1tb6/bt2+f279/vfvWrX7nMzEz3r3/9a9zOfMbhw4fdzJkz3ZIlS9zPf/7zsRn2//E6c09Pj1uwYIG78cYb3XvvvecOHz7smpubXVtb27id+YUXXnB+v9+98MIL7vDhw+7NN990ubm5btWqVWM2c0NDg1u7dq175ZVXnKQBf3D+Te3t7e6CCy5w4XDYffzxx+7JJ590aWlprrGx0dN1x0WAFi5c6CoqKpI/9/X1uRkzZrjq6upBz7/lllvcTTfd1G+tsLDQ/frXvx7VOf9/Xmf+ptOnT7upU6e6559/frRGHGA4M58+fdotWrTI/fnPf3bl5eVjHiCvMz/11FNu9uzZrre3d6xGHMDrzBUVFe6nP/1pv7VwOOwWL148qnMO5WwC9OCDD7orr7yy31ppaakrLi72dC3zp2C9vb1qbW1VKBRKrqWmpioUCqmlpWXQPS0tLf3Ol6Ti4uIhzx9pw5n5m06cOKFTp06N+F8XD2W4Mz/66KPKzs7W7bffPhZj9jOcmV9//XUVFRWpoqJCgUBAV111lTZt2qS+vr5xO/OiRYvU2tqafJrW3t6uhoYG3XjjjWMy83CM1H3Q/K/hx+orPkbScGb+ptWrV2vGjBkD/iGOluHM/N577+mZZ55RW1vbGEw40HBmbm9v19///nfddtttamho0KFDh3Tvvffq1KlTqqqqGpczL1++XF1dXbruuuvknNPp06d1991366GHHhr1eYdrqPtgPB7XV199pSlTppzV7Zg/Ajofbd68Wbt27dKrr76q9PR063EGdfz4ca1YsUJ1dXXKysqyHuesJRIJZWdn6+mnn1ZBQYFKS0u1du3aIb99czxobm7Wpk2btH37du3du1evvPKKdu/erY0bN1qPNurMHwFNxK/4GM7MZ2zZskWbN2/W22+/rXnz5o3mmP14nfnTTz/VZ599ppKSkuRaIpGQJE2aNEkHDx7UnDlzxtXMkpSbm6vJkycrLS0tuXb55ZcrEomot7dXPp9v3M28bt06rVixQnfccYck6eqrr1Z3d7fuuusurV27dsS/g2ckDHUfzMjIOOtHP9I4eAQ0Eb/iYzgzS9ITTzyhjRs3qrGxUQsWLBiLUZO8znzZZZfpww8/VFtbW/K4+eabdf3116utrU3BYHDczSxJixcv1qFDh5KxlKRPPvlEubm5ox6f4c584sSJAZE5E1A3Tv9Uc8Tug95eHx8dFl/xMdYzb9682fl8Pvfyyy+7f//738nj+PHj43bmb7J4F8zrzB0dHW7q1KnuN7/5jTt48KB74403XHZ2tnvsscfG7cxVVVVu6tSp7i9/+Ytrb293f/vb39ycOXPcLbfcMmYzHz9+3O3bt8/t27fPSXJbt251+/btc59//rlzzrk1a9a4FStWJM8/8zb87373O7d//35XW1s7cd+Gd25ifsWHl5kvvvjiQb/ku6qqatzO/E0WAXLO+8wffPCBKywsdH6/382ePds9/vjj7vTp0+N25lOnTrlHHnnEzZkzx6Wnp7tgMOjuvfde95///GfM5n3nnXcG/ffzzJzl5eVu6dKlA/bk5+c7n8/nZs+e7Z577jnP1+XrOACYMX8NCMD5iwABMEOAAJghQADMECAAZggQADMECIAZAgTADAECYIYAATBDgACY+T+wEjtFJei6JAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "# set range to [0,1] for matplotlib\n",
    "plt.imshow(mask[0], vmin=0, vmax=1)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(pred[0][0].detach().numpy(), vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
