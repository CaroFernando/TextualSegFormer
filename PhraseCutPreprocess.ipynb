{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT_PATH:  c:/Users/david/OneDrive/Documents/GitHub/TextualSegFormer\n",
      "DATASET_JSON_PATH:  c:/Users/david/OneDrive/Documents/GitHub/TextualSegFormer/Dataset/annotations_trainval2017/annotations/\n",
      "DATASET_TRAIN_IMAGES_PATH:  c:/Users/david/OneDrive/Documents/GitHub/TextualSegFormer/Dataset/train2017\n",
      "DATASET_VAL_IMAGES_PATH:  c:/Users/david/OneDrive/Documents/GitHub/TextualSegFormer/Dataset/val2017\n",
      "DATASET_TEST_IMAGES_PATH:  c:/Users/david/OneDrive/Documents/GitHub/TextualSegFormer/Dataset/test2017\n"
     ]
    }
   ],
   "source": [
    "CURRENT_PATH = os.getcwd()\n",
    "CURRENT_PATH = CURRENT_PATH.replace('\\\\', '/')\n",
    "\n",
    "DATASET_JSON_PATH = CURRENT_PATH + '/Dataset/annotations_trainval2017/annotations/'\n",
    "DATASET_TRAIN_IMAGES_PATH = CURRENT_PATH + '/Dataset/train2017'\n",
    "DATASET_VAL_IMAGES_PATH = CURRENT_PATH + '/Dataset/val2017'\n",
    "DATASET_TEST_IMAGES_PATH = CURRENT_PATH + '/Dataset/test2017'\n",
    "\n",
    "print('CURRENT_PATH: ', CURRENT_PATH)\n",
    "print('DATASET_JSON_PATH: ', DATASET_JSON_PATH)\n",
    "print('DATASET_TRAIN_IMAGES_PATH: ', DATASET_TRAIN_IMAGES_PATH)\n",
    "print('DATASET_VAL_IMAGES_PATH: ', DATASET_VAL_IMAGES_PATH)\n",
    "print('DATASET_TEST_IMAGES_PATH: ', DATASET_TEST_IMAGES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:/Users/david/OneDrive/Documents/GitHub/TextualSegFormer/ProcessedDataset/images\n",
      "c:/Users/david/OneDrive/Documents/GitHub/TextualSegFormer/ProcessedDataset/masks\n",
      "c:/Users/david/OneDrive/Documents/GitHub/TextualSegFormer/ProcessedDataset/instances\n"
     ]
    }
   ],
   "source": [
    "IMAGES_PATH = CURRENT_PATH + '/ProcessedDataset/images'\n",
    "MASKS_PATH = CURRENT_PATH + '/ProcessedDataset/masks'\n",
    "INSTANCES_PATH = CURRENT_PATH + '/ProcessedDataset/instances'\n",
    "\n",
    "print(IMAGES_PATH)\n",
    "print(MASKS_PATH)\n",
    "print(INSTANCES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_path_train = DATASET_JSON_PATH + 'captions_train2017.json'\n",
    "captions_path_val = DATASET_JSON_PATH + 'captions_val2017.json'\n",
    "\n",
    "instances_path_train = DATASET_JSON_PATH + 'instances_train2017.json'\n",
    "instances_path_val = DATASET_JSON_PATH + 'instances_val2017.json'\n",
    "\n",
    "keypoints_path_train = DATASET_JSON_PATH + 'person_keypoints_train2017.json'\n",
    "keypoints_path_val = DATASET_JSON_PATH + 'person_keypoints_val2017.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_zeros_id(id):\n",
    "    str_id = str(id)\n",
    "    str_id = '0'*(12-len(str_id)) + str_id\n",
    "    return str(str_id)\n",
    "\n",
    "def get_captions_dict(captions_json):\n",
    "    captions_dict = {}\n",
    "    for i in captions_json:\n",
    "        idx = fill_zeros_id(i['image_id'])\n",
    "        if idx not in captions_dict:\n",
    "            captions_dict[idx] = []\n",
    "        captions_dict[fill_zeros_id(i['image_id'])].append(i['caption'])\n",
    "    return captions_dict\n",
    "\n",
    "def get_categories_dict(categories_json):\n",
    "    categories_dict = {}\n",
    "    for i in categories_json:\n",
    "        categories_dict[i['id']] = {\n",
    "            'name': i['name'],\n",
    "            'supercategory': i['supercategory']\n",
    "        }\n",
    "    return categories_dict\n",
    "\n",
    "def get_mask_count(instances_json):\n",
    "    mask_count = {}\n",
    "    for i in instances_json:\n",
    "        idx = fill_zeros_id(i['image_id'])\n",
    "        if idx not in mask_count:\n",
    "            mask_count[idx] = 0\n",
    "        mask_count[idx] += 1\n",
    "    return mask_count\n",
    "\n",
    "def join_mask_annotations(instances_json):\n",
    "    images_annotations = {}\n",
    "    mask_count = {}\n",
    "    for i in range(len(instances_json['annotations'])):\n",
    "        idx = fill_zeros_id(instances_json['annotations'][i]['image_id'])\n",
    "        category_id = instances_json['annotations'][i]['category_id']\n",
    "        if idx not in images_annotations:\n",
    "            images_annotations[idx] = {}\n",
    "        if category_id not in images_annotations[idx]:\n",
    "            images_annotations[idx][category_id] = []\n",
    "        images_annotations[idx][category_id].append(instances_json['annotations'][i])\n",
    "\n",
    "        if idx not in mask_count:\n",
    "            mask_count[idx] = []\n",
    "        mask_count[idx].append(instances_json['annotations'][i]['category_id'])\n",
    "\n",
    "    return images_annotations, mask_count\n",
    "\n",
    "def preprocess_split(instances_json, captions_values, instance_categories, DATASET_IMAGES_PATH, IMAGES_PATH, MASKS_PATH, storeCaptions=True):\n",
    "\n",
    "    idx = 0\n",
    "    images, captions, masks, category, supercategory, category_id, mask_num = [], [], [], [], [], [], []\n",
    "    captions_dict = get_captions_dict(captions_values)\n",
    "    categories_dict = get_categories_dict(instance_categories)\n",
    "\n",
    "    images_annotations, mask_count = join_mask_annotations(instances_json)\n",
    "\n",
    "    if not os.path.exists(IMAGES_PATH):\n",
    "        os.makedirs(IMAGES_PATH)\n",
    "    if not os.path.exists(MASKS_PATH):\n",
    "        os.makedirs(MASKS_PATH)\n",
    "\n",
    "    for i in tqdm(images_annotations):\n",
    "\n",
    "        img_str_filled = fill_zeros_id(i)\n",
    "        image_str_name = img_str_filled + '.jpg'\n",
    "        img_path = DATASET_IMAGES_PATH + '/' + image_str_name\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            print('no existe alv')\n",
    "            continue\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)       \n",
    "\n",
    "        for j in images_annotations[i]:\n",
    "\n",
    "            # print(i, images_annotations[i][j][0]['category_id'], len(images_annotations[i][j]), mask_count[img_str_filled])\n",
    "            cat_id = images_annotations[i][j][0]['category_id']\n",
    "            image_str_name_idx = img_str_filled + '_' + str(idx) + '.jpg'\n",
    "            mask = np.zeros_like(img)\n",
    "            \n",
    "            for pts in images_annotations[i][j][0]['segmentation']:\n",
    "\n",
    "                pts = np.array(pts, dtype=np.float32)\n",
    "                pts = pts.reshape(-1, 2)\n",
    "                cv2.fillPoly(mask, [pts.astype(np.int32)], (255, 255, 255))\n",
    "                    \n",
    "            mask = cv2.resize(mask, (256, 256))\n",
    "            mask = cv2.cvtColor(mask, cv2.COLOR_RGB2BGR)\n",
    "            cv2.imwrite(MASKS_PATH + '/' + image_str_name_idx, mask)\n",
    "\n",
    "            if len(mask_count[img_str_filled]) > 1 and storeCaptions:\n",
    "                images.append(image_str_name)\n",
    "                captions.append(captions_dict[img_str_filled][0])\n",
    "                masks.append(image_str_name_idx)\n",
    "                category.append(categories_dict[cat_id]['name'])\n",
    "                supercategory.append(categories_dict[cat_id]['supercategory'])\n",
    "                category_id.append(cat_id)\n",
    "                mask_num.append(len(mask_count[img_str_filled]))\n",
    "            else:\n",
    "                for cap in captions_dict[img_str_filled]:\n",
    "                    images.append(image_str_name)\n",
    "                    captions.append(cap)\n",
    "                    masks.append(image_str_name_idx)\n",
    "                    category.append(categories_dict[cat_id]['name'])\n",
    "                    supercategory.append(categories_dict[cat_id]['supercategory'])\n",
    "                    category_id.append(cat_id)\n",
    "                    mask_num.append(len(mask_count[img_str_filled]))\n",
    "\n",
    "            idx += 1\n",
    "\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)    \n",
    "        cv2.imwrite(IMAGES_PATH + '/' + image_str_name, img)    \n",
    "\n",
    "        if idx > 30:\n",
    "            break\n",
    "\n",
    "    df = pd.DataFrame({'image': images, 'mask': masks, 'captions': captions, 'label': category, 'supercategory': supercategory, 'category_id': category_id, 'mask_num': mask_num})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(instances_path_train) as f:\n",
    "    instances_train_json = json.load(f)\n",
    "with open(captions_path_train) as f:\n",
    "    captions_train_json = json.load(f)\n",
    "\n",
    "with open(instances_path_val) as f:\n",
    "    instances_val_json = json.load(f)\n",
    "with open(captions_path_val) as f:\n",
    "    captions_val_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances dict_keys(['segmentation', 'area', 'iscrowd', 'image_id', 'bbox', 'category_id', 'id'])\n",
      "Captions dict_keys(['image_id', 'id', 'caption'])\n",
      "instance_categories [{'supercategory': 'person', 'id': 1, 'name': 'person'}, {'supercategory': 'vehicle', 'id': 2, 'name': 'bicycle'}, {'supercategory': 'vehicle', 'id': 3, 'name': 'car'}, {'supercategory': 'vehicle', 'id': 4, 'name': 'motorcycle'}, {'supercategory': 'vehicle', 'id': 5, 'name': 'airplane'}, {'supercategory': 'vehicle', 'id': 6, 'name': 'bus'}, {'supercategory': 'vehicle', 'id': 7, 'name': 'train'}, {'supercategory': 'vehicle', 'id': 8, 'name': 'truck'}, {'supercategory': 'vehicle', 'id': 9, 'name': 'boat'}, {'supercategory': 'outdoor', 'id': 10, 'name': 'traffic light'}, {'supercategory': 'outdoor', 'id': 11, 'name': 'fire hydrant'}, {'supercategory': 'outdoor', 'id': 13, 'name': 'stop sign'}, {'supercategory': 'outdoor', 'id': 14, 'name': 'parking meter'}, {'supercategory': 'outdoor', 'id': 15, 'name': 'bench'}, {'supercategory': 'animal', 'id': 16, 'name': 'bird'}, {'supercategory': 'animal', 'id': 17, 'name': 'cat'}, {'supercategory': 'animal', 'id': 18, 'name': 'dog'}, {'supercategory': 'animal', 'id': 19, 'name': 'horse'}, {'supercategory': 'animal', 'id': 20, 'name': 'sheep'}, {'supercategory': 'animal', 'id': 21, 'name': 'cow'}, {'supercategory': 'animal', 'id': 22, 'name': 'elephant'}, {'supercategory': 'animal', 'id': 23, 'name': 'bear'}, {'supercategory': 'animal', 'id': 24, 'name': 'zebra'}, {'supercategory': 'animal', 'id': 25, 'name': 'giraffe'}, {'supercategory': 'accessory', 'id': 27, 'name': 'backpack'}, {'supercategory': 'accessory', 'id': 28, 'name': 'umbrella'}, {'supercategory': 'accessory', 'id': 31, 'name': 'handbag'}, {'supercategory': 'accessory', 'id': 32, 'name': 'tie'}, {'supercategory': 'accessory', 'id': 33, 'name': 'suitcase'}, {'supercategory': 'sports', 'id': 34, 'name': 'frisbee'}, {'supercategory': 'sports', 'id': 35, 'name': 'skis'}, {'supercategory': 'sports', 'id': 36, 'name': 'snowboard'}, {'supercategory': 'sports', 'id': 37, 'name': 'sports ball'}, {'supercategory': 'sports', 'id': 38, 'name': 'kite'}, {'supercategory': 'sports', 'id': 39, 'name': 'baseball bat'}, {'supercategory': 'sports', 'id': 40, 'name': 'baseball glove'}, {'supercategory': 'sports', 'id': 41, 'name': 'skateboard'}, {'supercategory': 'sports', 'id': 42, 'name': 'surfboard'}, {'supercategory': 'sports', 'id': 43, 'name': 'tennis racket'}, {'supercategory': 'kitchen', 'id': 44, 'name': 'bottle'}, {'supercategory': 'kitchen', 'id': 46, 'name': 'wine glass'}, {'supercategory': 'kitchen', 'id': 47, 'name': 'cup'}, {'supercategory': 'kitchen', 'id': 48, 'name': 'fork'}, {'supercategory': 'kitchen', 'id': 49, 'name': 'knife'}, {'supercategory': 'kitchen', 'id': 50, 'name': 'spoon'}, {'supercategory': 'kitchen', 'id': 51, 'name': 'bowl'}, {'supercategory': 'food', 'id': 52, 'name': 'banana'}, {'supercategory': 'food', 'id': 53, 'name': 'apple'}, {'supercategory': 'food', 'id': 54, 'name': 'sandwich'}, {'supercategory': 'food', 'id': 55, 'name': 'orange'}, {'supercategory': 'food', 'id': 56, 'name': 'broccoli'}, {'supercategory': 'food', 'id': 57, 'name': 'carrot'}, {'supercategory': 'food', 'id': 58, 'name': 'hot dog'}, {'supercategory': 'food', 'id': 59, 'name': 'pizza'}, {'supercategory': 'food', 'id': 60, 'name': 'donut'}, {'supercategory': 'food', 'id': 61, 'name': 'cake'}, {'supercategory': 'furniture', 'id': 62, 'name': 'chair'}, {'supercategory': 'furniture', 'id': 63, 'name': 'couch'}, {'supercategory': 'furniture', 'id': 64, 'name': 'potted plant'}, {'supercategory': 'furniture', 'id': 65, 'name': 'bed'}, {'supercategory': 'furniture', 'id': 67, 'name': 'dining table'}, {'supercategory': 'furniture', 'id': 70, 'name': 'toilet'}, {'supercategory': 'electronic', 'id': 72, 'name': 'tv'}, {'supercategory': 'electronic', 'id': 73, 'name': 'laptop'}, {'supercategory': 'electronic', 'id': 74, 'name': 'mouse'}, {'supercategory': 'electronic', 'id': 75, 'name': 'remote'}, {'supercategory': 'electronic', 'id': 76, 'name': 'keyboard'}, {'supercategory': 'electronic', 'id': 77, 'name': 'cell phone'}, {'supercategory': 'appliance', 'id': 78, 'name': 'microwave'}, {'supercategory': 'appliance', 'id': 79, 'name': 'oven'}, {'supercategory': 'appliance', 'id': 80, 'name': 'toaster'}, {'supercategory': 'appliance', 'id': 81, 'name': 'sink'}, {'supercategory': 'appliance', 'id': 82, 'name': 'refrigerator'}, {'supercategory': 'indoor', 'id': 84, 'name': 'book'}, {'supercategory': 'indoor', 'id': 85, 'name': 'clock'}, {'supercategory': 'indoor', 'id': 86, 'name': 'vase'}, {'supercategory': 'indoor', 'id': 87, 'name': 'scissors'}, {'supercategory': 'indoor', 'id': 88, 'name': 'teddy bear'}, {'supercategory': 'indoor', 'id': 89, 'name': 'hair drier'}, {'supercategory': 'indoor', 'id': 90, 'name': 'toothbrush'}]\n",
      "Len Instances set 4952\n",
      "Len captions set 5000\n",
      "Len Instances 36781\n",
      "Len Captions 25014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/4952 [00:00<01:19, 62.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              image                mask  \\\n",
      "0  000000289343.jpg  000000289343_0.jpg   \n",
      "1  000000289343.jpg  000000289343_1.jpg   \n",
      "2  000000289343.jpg  000000289343_2.jpg   \n",
      "3  000000289343.jpg  000000289343_3.jpg   \n",
      "4  000000061471.jpg  000000061471_4.jpg   \n",
      "\n",
      "                                          captions    label supercategory  \\\n",
      "0   A man is riding a large bike through the park.      dog        animal   \n",
      "1   A man is riding a large bike through the park.   person        person   \n",
      "2   A man is riding a large bike through the park.    bench       outdoor   \n",
      "3   A man is riding a large bike through the park.  bicycle       vehicle   \n",
      "4  Puppy chewing on toilet paper in the bathroom.       dog        animal   \n",
      "\n",
      "   category_id  mask_num  \n",
      "0           18         4  \n",
      "1            1         4  \n",
      "2           15         4  \n",
      "3            2         4  \n",
      "4           18         3  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "instances_val = instances_val_json['annotations']\n",
    "captions_val = captions_val_json['annotations']\n",
    "\n",
    "instance_categories = instances_val_json['categories']\n",
    "\n",
    "print('Instances', instances_val[0].keys())\n",
    "print('Captions', captions_val[0].keys())\n",
    "print('instance_categories', instance_categories)\n",
    "\n",
    "instances_set = set([i['image_id'] for i in instances_val])\n",
    "captions_set = set([i['image_id'] for i in captions_val])\n",
    "\n",
    "print('Len Instances set', len(instances_set))\n",
    "print('Len captions set', len(captions_set))\n",
    "\n",
    "print('Len Instances', len(instances_val))\n",
    "print('Len Captions', len(captions_val))\n",
    "\n",
    "df = preprocess_split(instances_val_json, captions_val, instance_categories, DATASET_VAL_IMAGES_PATH, IMAGES_PATH + '/val/', MASKS_PATH + '/val/')\n",
    "print(df.head())\n",
    "df.to_csv('val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances dict_keys(['segmentation', 'area', 'iscrowd', 'image_id', 'bbox', 'category_id', 'id'])\n",
      "Captions dict_keys(['image_id', 'id', 'caption'])\n",
      "instance_categories [{'supercategory': 'person', 'id': 1, 'name': 'person'}, {'supercategory': 'vehicle', 'id': 2, 'name': 'bicycle'}, {'supercategory': 'vehicle', 'id': 3, 'name': 'car'}, {'supercategory': 'vehicle', 'id': 4, 'name': 'motorcycle'}, {'supercategory': 'vehicle', 'id': 5, 'name': 'airplane'}, {'supercategory': 'vehicle', 'id': 6, 'name': 'bus'}, {'supercategory': 'vehicle', 'id': 7, 'name': 'train'}, {'supercategory': 'vehicle', 'id': 8, 'name': 'truck'}, {'supercategory': 'vehicle', 'id': 9, 'name': 'boat'}, {'supercategory': 'outdoor', 'id': 10, 'name': 'traffic light'}, {'supercategory': 'outdoor', 'id': 11, 'name': 'fire hydrant'}, {'supercategory': 'outdoor', 'id': 13, 'name': 'stop sign'}, {'supercategory': 'outdoor', 'id': 14, 'name': 'parking meter'}, {'supercategory': 'outdoor', 'id': 15, 'name': 'bench'}, {'supercategory': 'animal', 'id': 16, 'name': 'bird'}, {'supercategory': 'animal', 'id': 17, 'name': 'cat'}, {'supercategory': 'animal', 'id': 18, 'name': 'dog'}, {'supercategory': 'animal', 'id': 19, 'name': 'horse'}, {'supercategory': 'animal', 'id': 20, 'name': 'sheep'}, {'supercategory': 'animal', 'id': 21, 'name': 'cow'}, {'supercategory': 'animal', 'id': 22, 'name': 'elephant'}, {'supercategory': 'animal', 'id': 23, 'name': 'bear'}, {'supercategory': 'animal', 'id': 24, 'name': 'zebra'}, {'supercategory': 'animal', 'id': 25, 'name': 'giraffe'}, {'supercategory': 'accessory', 'id': 27, 'name': 'backpack'}, {'supercategory': 'accessory', 'id': 28, 'name': 'umbrella'}, {'supercategory': 'accessory', 'id': 31, 'name': 'handbag'}, {'supercategory': 'accessory', 'id': 32, 'name': 'tie'}, {'supercategory': 'accessory', 'id': 33, 'name': 'suitcase'}, {'supercategory': 'sports', 'id': 34, 'name': 'frisbee'}, {'supercategory': 'sports', 'id': 35, 'name': 'skis'}, {'supercategory': 'sports', 'id': 36, 'name': 'snowboard'}, {'supercategory': 'sports', 'id': 37, 'name': 'sports ball'}, {'supercategory': 'sports', 'id': 38, 'name': 'kite'}, {'supercategory': 'sports', 'id': 39, 'name': 'baseball bat'}, {'supercategory': 'sports', 'id': 40, 'name': 'baseball glove'}, {'supercategory': 'sports', 'id': 41, 'name': 'skateboard'}, {'supercategory': 'sports', 'id': 42, 'name': 'surfboard'}, {'supercategory': 'sports', 'id': 43, 'name': 'tennis racket'}, {'supercategory': 'kitchen', 'id': 44, 'name': 'bottle'}, {'supercategory': 'kitchen', 'id': 46, 'name': 'wine glass'}, {'supercategory': 'kitchen', 'id': 47, 'name': 'cup'}, {'supercategory': 'kitchen', 'id': 48, 'name': 'fork'}, {'supercategory': 'kitchen', 'id': 49, 'name': 'knife'}, {'supercategory': 'kitchen', 'id': 50, 'name': 'spoon'}, {'supercategory': 'kitchen', 'id': 51, 'name': 'bowl'}, {'supercategory': 'food', 'id': 52, 'name': 'banana'}, {'supercategory': 'food', 'id': 53, 'name': 'apple'}, {'supercategory': 'food', 'id': 54, 'name': 'sandwich'}, {'supercategory': 'food', 'id': 55, 'name': 'orange'}, {'supercategory': 'food', 'id': 56, 'name': 'broccoli'}, {'supercategory': 'food', 'id': 57, 'name': 'carrot'}, {'supercategory': 'food', 'id': 58, 'name': 'hot dog'}, {'supercategory': 'food', 'id': 59, 'name': 'pizza'}, {'supercategory': 'food', 'id': 60, 'name': 'donut'}, {'supercategory': 'food', 'id': 61, 'name': 'cake'}, {'supercategory': 'furniture', 'id': 62, 'name': 'chair'}, {'supercategory': 'furniture', 'id': 63, 'name': 'couch'}, {'supercategory': 'furniture', 'id': 64, 'name': 'potted plant'}, {'supercategory': 'furniture', 'id': 65, 'name': 'bed'}, {'supercategory': 'furniture', 'id': 67, 'name': 'dining table'}, {'supercategory': 'furniture', 'id': 70, 'name': 'toilet'}, {'supercategory': 'electronic', 'id': 72, 'name': 'tv'}, {'supercategory': 'electronic', 'id': 73, 'name': 'laptop'}, {'supercategory': 'electronic', 'id': 74, 'name': 'mouse'}, {'supercategory': 'electronic', 'id': 75, 'name': 'remote'}, {'supercategory': 'electronic', 'id': 76, 'name': 'keyboard'}, {'supercategory': 'electronic', 'id': 77, 'name': 'cell phone'}, {'supercategory': 'appliance', 'id': 78, 'name': 'microwave'}, {'supercategory': 'appliance', 'id': 79, 'name': 'oven'}, {'supercategory': 'appliance', 'id': 80, 'name': 'toaster'}, {'supercategory': 'appliance', 'id': 81, 'name': 'sink'}, {'supercategory': 'appliance', 'id': 82, 'name': 'refrigerator'}, {'supercategory': 'indoor', 'id': 84, 'name': 'book'}, {'supercategory': 'indoor', 'id': 85, 'name': 'clock'}, {'supercategory': 'indoor', 'id': 86, 'name': 'vase'}, {'supercategory': 'indoor', 'id': 87, 'name': 'scissors'}, {'supercategory': 'indoor', 'id': 88, 'name': 'teddy bear'}, {'supercategory': 'indoor', 'id': 89, 'name': 'hair drier'}, {'supercategory': 'indoor', 'id': 90, 'name': 'toothbrush'}]\n",
      "Len Instances set 117266\n",
      "Len captions set 118287\n",
      "Len Instances 860001\n",
      "Len Captions 591753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/117266 [00:00<40:51, 47.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              image                mask  \\\n",
      "0  000000558840.jpg  000000558840_0.jpg   \n",
      "1  000000558840.jpg  000000558840_1.jpg   \n",
      "2  000000558840.jpg  000000558840_2.jpg   \n",
      "3  000000558840.jpg  000000558840_3.jpg   \n",
      "4  000000558840.jpg  000000558840_4.jpg   \n",
      "\n",
      "                                            captions    label supercategory  \\\n",
      "0  Tray of food disguised in car, on restaurant c...  hot dog          food   \n",
      "1  Tray of food disguised in car, on restaurant c...   bottle       kitchen   \n",
      "2  Tray of food disguised in car, on restaurant c...      cup       kitchen   \n",
      "3  Tray of food disguised in car, on restaurant c...   person        person   \n",
      "4  Tray of food disguised in car, on restaurant c...    spoon       kitchen   \n",
      "\n",
      "   category_id  mask_num  \n",
      "0           58        11  \n",
      "1           44        11  \n",
      "2           47        11  \n",
      "3            1        11  \n",
      "4           50        11  \n"
     ]
    }
   ],
   "source": [
    "instances_train = instances_train_json['annotations']\n",
    "captions_train = captions_train_json['annotations']\n",
    "\n",
    "instance_categories = instances_train_json['categories']\n",
    "\n",
    "print('Instances', instances_train[0].keys())\n",
    "print('Captions', captions_train[0].keys())\n",
    "print('instance_categories', instance_categories)\n",
    "\n",
    "instances_set = set([i['image_id'] for i in instances_train])\n",
    "captions_set = set([i['image_id'] for i in captions_train])\n",
    "\n",
    "print('Len Instances set', len(instances_set))\n",
    "print('Len captions set', len(captions_set))\n",
    "\n",
    "print('Len Instances', len(instances_train))\n",
    "print('Len Captions', len(captions_train))\n",
    "\n",
    "df = preprocess_split(instances_train_json, captions_train, instance_categories, DATASET_TRAIN_IMAGES_PATH, IMAGES_PATH + '/train/', MASKS_PATH + '/train/')\n",
    "print(df.head())\n",
    "df.to_csv('train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in captions_val:\n",
    "    if x['image_id'] == 558840:\n",
    "        print(x['caption'])\n",
    "        print(x)\n",
    "\n",
    "for x in instances_val:\n",
    "    if x['image_id'] == 558840:\n",
    "\n",
    "        print(x['image_id'], x['bbox'], x['area'], x['iscrowd'], x['category_id'], x['id'])\n",
    "        \n",
    "        img = cv2.imread(DATASET_VAL_IMAGES_PATH + '/' + fill_zeros_id(x['image_id']) + '.jpg')\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        mask = np.zeros_like(img)\n",
    "        pts = np.array(x['segmentation'][0], dtype=np.float32)\n",
    "        pts = pts.reshape(-1, 2)\n",
    "        cv2.fillPoly(mask, [pts.astype(np.int32)], (255, 255, 255))\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(img)\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(mask)\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(img)\n",
    "        plt.imshow(mask, alpha=0.5)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
