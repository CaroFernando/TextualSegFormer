{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from pycocotools import mask as cocomask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_PATH = os.getcwd()\n",
    "CURRENT_PATH = CURRENT_PATH.replace('\\\\', '/')\n",
    "\n",
    "DATASET_STUFF_JSON_PATH = CURRENT_PATH + '/Dataset/stuff_annotations_trainval2017/annotations/'\n",
    "DATASET_JSON_PATH = CURRENT_PATH + '/Dataset/annotations_trainval2017/annotations/'\n",
    "\n",
    "DATASET_TRAIN_IMAGES_PATH = CURRENT_PATH + '/Dataset/train2017'\n",
    "DATASET_VAL_IMAGES_PATH = CURRENT_PATH + '/Dataset/val2017'\n",
    "DATASET_TEST_IMAGES_PATH = CURRENT_PATH + '/Dataset/test2017'\n",
    "\n",
    "print('CURRENT_PATH: ', CURRENT_PATH)\n",
    "print('DATASET_JSON_PATH: ', DATASET_JSON_PATH)\n",
    "print('DATASET_TRAIN_IMAGES_PATH: ', DATASET_TRAIN_IMAGES_PATH)\n",
    "print('DATASET_VAL_IMAGES_PATH: ', DATASET_VAL_IMAGES_PATH)\n",
    "print('DATASET_TEST_IMAGES_PATH: ', DATASET_TEST_IMAGES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = CURRENT_PATH + '/ProcessedDatasetStuff/images'\n",
    "MASKS_PATH = CURRENT_PATH + '/ProcessedDatasetStuff/masks'\n",
    "CSV_PATH = CURRENT_PATH + '/ProcessedDatasetStuff/csv'\n",
    "\n",
    "print(IMAGES_PATH)\n",
    "print(MASKS_PATH)\n",
    "print(CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_stuff_path_train = DATASET_STUFF_JSON_PATH + 'stuff_train2017.json'\n",
    "instances_stuff_path_val = DATASET_STUFF_JSON_PATH + 'stuff_val2017.json'\n",
    "\n",
    "instances_path_train = DATASET_JSON_PATH + 'instances_train2017.json'\n",
    "instances_path_val = DATASET_JSON_PATH + 'instances_val2017.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(instances_stuff_path_train) as f:\n",
    "    instances_stuff_train_json = json.load(f)\n",
    "with open(instances_stuff_path_val) as f:\n",
    "    instances_stuff_val_json = json.load(f)\n",
    "\n",
    "with open(instances_path_train) as f:\n",
    "    instances_train_json = json.load(f)\n",
    "with open(instances_path_val) as f:\n",
    "    instances_val_json = json.load(f)\n",
    "\n",
    "with open(CURRENT_PATH + '/labels.json') as f:\n",
    "    categories_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_class = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, \n",
    "20, 21, 22, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, \n",
    "44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, \n",
    "65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, \n",
    "86, 87, 89, 90, 91, 92, 93, 95, 96, 97, 98,  99, 100, 101, 102, 103, 104, 105, \n",
    "106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, \n",
    "123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 134, 135, 138, 139, 140, 141, \n",
    "142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, \n",
    "159, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170]\n",
    "novel_class = [19, 23, 28, 29, 36, 51, 76, 88, 94, 112, 133, 136, 137, 157, 160]\n",
    "both_class = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, \n",
    "19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, \n",
    "39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, \n",
    "59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, \n",
    "79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n",
    "99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, \n",
    "115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, \n",
    "131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, \n",
    "147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, \n",
    "163, 164, 165, 166, 167, 168, 169, 170]\n",
    "\n",
    "print(len(both_class))\n",
    "\n",
    "seen_categories = []\n",
    "\n",
    "for i in range(len(instances_val_json['annotations'])):\n",
    "    category_id = instances_val_json['annotations'][i]['category_id']\n",
    "    if category_id not in seen_categories:\n",
    "        seen_categories.append(category_id)\n",
    "\n",
    "for i in range(len(instances_stuff_val_json['annotations'])):\n",
    "    category_id = instances_stuff_val_json['annotations'][i]['category_id']\n",
    "    if category_id not in seen_categories:\n",
    "        seen_categories.append(category_id)\n",
    "\n",
    "print('Number of classes: ', len(seen_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_class_names = []\n",
    "novel_class_names = []\n",
    "both_class_names = []\n",
    "\n",
    "for i in range(len(base_class)):\n",
    "    base_class_names.append(categories_dict[str(base_class[i])])\n",
    "\n",
    "for i in range(len(novel_class)):\n",
    "    novel_class_names.append(categories_dict[str(novel_class[i])])\n",
    "\n",
    "for i in range(len(both_class)):\n",
    "    both_class_names.append(categories_dict[str(both_class[i])])\n",
    "\n",
    "print('base_class_names: ', base_class_names)\n",
    "print('novel_class_names: ', novel_class_names)\n",
    "print('both_class_names: ', both_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_zeros_id(id):\n",
    "    str_id = str(id)\n",
    "    str_id = '0'*(12-len(str_id)) + str_id\n",
    "    return str(str_id)\n",
    "\n",
    "def join_mask_annotations(instances_json):\n",
    "    images_annotations = {}\n",
    "    for i in range(len(instances_json['annotations'])):\n",
    "        idx = fill_zeros_id(instances_json['annotations'][i]['image_id'])\n",
    "        category_id = instances_json['annotations'][i]['category_id']\n",
    "        if idx not in images_annotations:\n",
    "            images_annotations[idx] = {}\n",
    "        if category_id not in images_annotations[idx]:\n",
    "            images_annotations[idx][category_id] = []\n",
    "        images_annotations[idx][category_id].append(instances_json['annotations'][i])\n",
    "\n",
    "    return images_annotations\n",
    "\n",
    "def save_img(mask, path):\n",
    "    mask = cv2.resize(mask, (256, 256))\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(path, mask)\n",
    "    return\n",
    "\n",
    "def preprocess_img(i, DATASET_IMAGES_PATH):\n",
    "    img_str_filled = fill_zeros_id(i)\n",
    "    image_str_name = img_str_filled + '.jpg'\n",
    "    img_path = DATASET_IMAGES_PATH + '/' + image_str_name\n",
    "    if not os.path.exists(img_path):\n",
    "        # print('no existe alv')\n",
    "        return None, img_str_filled, image_str_name\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)     \n",
    "    return img, img_str_filled, image_str_name\n",
    "\n",
    "def decode_rle(rle_counts, size):\n",
    "    height, width = size\n",
    "    rle_encoding = [{'size': (height, width), 'counts': rle_counts}]\n",
    "    mask = cocomask.decode(rle_encoding)\n",
    "    mask_array = np.array(mask, dtype=np.uint8)\n",
    "    return mask_array\n",
    "\n",
    "def preprocess_split(instances_json, instances_stuff_json, DATASET_IMAGES_PATH, IMAGES_PATH, MASKS_PATH, CSV_PATH):\n",
    "\n",
    "    idx = 0\n",
    "    images, masks, category, category_id  = [], [], [], []\n",
    "\n",
    "    images_annotations = join_mask_annotations(instances_json)\n",
    "\n",
    "    if os.path.exists(IMAGES_PATH):\n",
    "        os.system('rm -rf ' + IMAGES_PATH)\n",
    "    if os.path.exists(MASKS_PATH):\n",
    "        os.system('rm -rf ' + MASKS_PATH)\n",
    "\n",
    "    if not os.path.exists(IMAGES_PATH):\n",
    "        os.makedirs(IMAGES_PATH)\n",
    "    if not os.path.exists(MASKS_PATH):\n",
    "        os.makedirs(MASKS_PATH)\n",
    "    if not os.path.exists(CSV_PATH):\n",
    "        os.makedirs(CSV_PATH)\n",
    "        \n",
    "    for i in tqdm(images_annotations):\n",
    "        img, img_str_filled, image_str_name = preprocess_img(i, DATASET_IMAGES_PATH)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        for j in images_annotations[i]:\n",
    "\n",
    "            cat_id = images_annotations[i][j][0]['category_id']\n",
    "            image_str_name_idx = img_str_filled + '_' + str(idx) + '.jpg'\n",
    "            mask = np.zeros_like(img)\n",
    "            \n",
    "            for pts in images_annotations[i][j][0]['segmentation']:\n",
    "                pts = np.array(pts, dtype=np.float32)\n",
    "                pts = pts.reshape(-1, 2)\n",
    "                cv2.fillPoly(mask, [pts.astype(np.int32)], (255, 255, 255))\n",
    "                    \n",
    "            save_img(mask, MASKS_PATH + '/' + image_str_name_idx)\n",
    "\n",
    "            images.append(image_str_name)\n",
    "            masks.append(image_str_name_idx)\n",
    "            category.append(categories_dict[str(cat_id)])\n",
    "            category_id.append(cat_id)\n",
    "\n",
    "            idx += 1\n",
    "        \n",
    "        save_img(img, IMAGES_PATH + '/' + image_str_name)\n",
    "    \n",
    "    for i in tqdm(instances_stuff_json):\n",
    "\n",
    "        id = i['image_id']\n",
    "        img, img_str_filled, image_str_name = preprocess_img(id, DATASET_IMAGES_PATH)\n",
    "        if img is None:\n",
    "            continue         \n",
    "\n",
    "        cat_id = i['category_id']\n",
    "        if str(cat_id) not in categories_dict:\n",
    "            continue   \n",
    "\n",
    "        image_str_name_idx = img_str_filled + '_' + str(idx) + '.jpg'\n",
    "        \n",
    "        size = i['segmentation']['size']\n",
    "        rle_counts = i['segmentation']['counts']\n",
    "\n",
    "        mask = decode_rle(rle_counts, size)\n",
    "        mask = (mask - np.min(mask)) * (255 / (np.max(mask) - np.min(mask)))\n",
    "        mask = mask.astype(np.uint8)\n",
    "                \n",
    "        save_img(mask, MASKS_PATH + '/' + image_str_name_idx)\n",
    "        save_img(img, IMAGES_PATH + '/' + image_str_name)\n",
    "\n",
    "        images.append(image_str_name)\n",
    "        masks.append(image_str_name_idx)\n",
    "        category.append(categories_dict[str(cat_id)])\n",
    "        category_id.append(cat_id)\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "    df = pd.DataFrame({'image': images, 'mask': masks, 'label': category, 'category_id': category_id})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess_split(instances_val_json, instances_stuff_val_json['annotations'], DATASET_VAL_IMAGES_PATH, IMAGES_PATH + '/val/', MASKS_PATH + '/val/', CSV_PATH)\n",
    "df.to_csv(CSV_PATH + '/val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117266/117266 [33:33<00:00, 58.23it/s]\n",
      "  3%|▎         | 25920/747458 [03:31<1:36:34, 124.52it/s]C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20640\\3297055612.py:106: RuntimeWarning: divide by zero encountered in divide\n",
      "  mask = (mask - np.min(mask)) * (255 / (np.max(mask) - np.min(mask)))\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20640\\3297055612.py:106: RuntimeWarning: invalid value encountered in multiply\n",
      "  mask = (mask - np.min(mask)) * (255 / (np.max(mask) - np.min(mask)))\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20640\\3297055612.py:107: RuntimeWarning: invalid value encountered in cast\n",
      "  mask = mask.astype(np.uint8)\n",
      "100%|██████████| 747458/747458 [1:45:53<00:00, 117.65it/s]\n"
     ]
    }
   ],
   "source": [
    "df = preprocess_split(instances_train_json, instances_stuff_train_json['annotations'], DATASET_TRAIN_IMAGES_PATH, IMAGES_PATH + '/train/', MASKS_PATH + '/train/', CSV_PATH)\n",
    "df.to_csv(CSV_PATH + '/train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation = instances_stuff_val_json['annotations'][0]\n",
    "print(annotation.keys())\n",
    "height, width = annotation['segmentation']['size']\n",
    "rle_counts = instances_stuff_val_json['annotations'][0]['segmentation']['counts']\n",
    "print(rle_counts)\n",
    "mask_array = decode_rle(rle_counts, (height, width))\n",
    "\n",
    "# print dtpye of mask_array\n",
    "print(mask_array.dtype)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Supongamos que tienes un numpy array llamado image_array\n",
    "\n",
    "# Normalizar el numpy array al rango de 0 a 255\n",
    "image_array = (mask_array - np.min(mask_array)) * (255 / (np.max(mask_array) - np.min(mask_array)))\n",
    "image_array = image_array.astype(np.uint8)\n",
    "\n",
    "# Guardar el array como imagen utilizando OpenCV\n",
    "cv2.imwrite('imagen.png', image_array)\n",
    "\n",
    "plt.imshow(mask_array, cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
